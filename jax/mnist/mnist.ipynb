{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from jax import numpy as jnp\n",
    "\n",
    "import flax\n",
    "from flax import linen as nn \n",
    "from flax import optim\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TpuDevice(id=0, task=0, coords=(0,0,0), core_on_chip=0), TpuDevice(id=1, task=0, coords=(0,0,0), core_on_chip=1), TpuDevice(id=2, task=0, coords=(1,0,0), core_on_chip=0), TpuDevice(id=3, task=0, coords=(1,0,0), core_on_chip=1), TpuDevice(id=4, task=0, coords=(0,1,0), core_on_chip=0), TpuDevice(id=5, task=0, coords=(0,1,0), core_on_chip=1), TpuDevice(id=6, task=0, coords=(1,1,0), core_on_chip=0), TpuDevice(id=7, task=0, coords=(1,1,0), core_on_chip=1)]\n"
     ]
    }
   ],
   "source": [
    "print(jax.devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mnist(nn.Module):\n",
    "    \"\"\".\"\"\"\n",
    "    def setup(self):\n",
    "        self.conv1 = nn.Conv(features=32, kernel_size=(3,3))\n",
    "        self.conv2 = nn.Conv(features=64, kernel_size=(2,2))\n",
    "        self.dens1 = nn.Dense(features=256)\n",
    "        self.dens2 = nn.Dense(features=10)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2,2), strides=(2,2))\n",
    "        x = self.conv2(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2,2), strides=(2,2))\n",
    "        x = x.reshape((x.shape[0], -1))\n",
    "        x = self.dens1(x)\n",
    "        x = nn.relu(x)\n",
    "        x = self.dens2(x)\n",
    "        x = nn.log_softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(logits, labels):\n",
    "    \"\"\" logits are assumed to be log(p^) \"\"\"\n",
    "    one_hot_labels = jax.nn.one_hot(labels, num_classes=10)\n",
    "    return -jnp.mean(jnp.sum(one_hot_labels * logits, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(params, **kwopts):\n",
    "    optimizer_def = optim.Adam(**kwopts)\n",
    "    return optimizer_def.create(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_params(key):\n",
    "    init_shape = np.ones((1, 28, 28, 1), jnp.float32)\n",
    "    initial_params = mnist().init(key, init_shape)['params']\n",
    "    return initial_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(logits, labels):\n",
    "    loss = cross_entropy_loss(logits, labels)\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
    "    metrics = {\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets():\n",
    "    ds_builder = tfds.builder('mnist')\n",
    "    ds_builder.download_and_prepare()\n",
    "    train_ds = tfds.as_numpy(ds_builder.as_dataset(split='train', batch_size=-1))\n",
    "    test_ds = tfds.as_numpy(ds_builder.as_dataset(split='test', batch_size=-1))\n",
    "    train_ds['image'] = jnp.float32(train_ds['image']) / 255.0\n",
    "    test_ds['image'] = jnp.float32(test_ds['image']) / 255.0\n",
    "    return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(optimizer, batch):\n",
    "    def loss_fn(params):\n",
    "        logits = mnist().apply({'params': params}, batch['image'])\n",
    "        loss = cross_entropy_loss(logits, batch['label'])\n",
    "        return loss, logits\n",
    "    \n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (_, logits), grad = grad_fn(optimizer.target)\n",
    "    optimizer = optimizer.apply_gradient(grad)\n",
    "    metrics = compute_metrics(logits, batch['label'])\n",
    "    return optimizer, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def eval_step(params, batch):\n",
    "    logits = mnist().apply({'params': params}, batch['image'])\n",
    "    return compute_metrics(logits, batch['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(optimizer, train_ds, batch_size, epoch, rng):\n",
    "    # Compute number of steps\n",
    "    train_ds_size = len(train_ds['image'])\n",
    "    steps_per_epoch = train_ds_size // batch_size\n",
    "    \n",
    "    #Shuffle the data\n",
    "    perms = jax.random.permutation(rng, train_ds_size)\n",
    "    perms = perms[:steps_per_epoch * batch_size] # drop incomplete batch\n",
    "    perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "    batch_metrics = []\n",
    "\n",
    "    \n",
    "    for perm in perms:\n",
    "        batch = {k: v[perm, ...] for k, v in train_ds.items()}\n",
    "        optimizer, metrics = train_step(optimizer, batch)\n",
    "        batch_metrics.append(metrics)\n",
    "    \n",
    "    train_batch_metrics = jax.device_get(batch_metrics)\n",
    "    train_epoch_metrics = {\n",
    "        k: np.mean([metrics[k] for metrics in train_batch_metrics])\n",
    "        for k in train_batch_metrics[0]\n",
    "    }\n",
    "    print(f\"Training - epoch: {epoch}, loss: {train_epoch_metrics['loss']}, accuracy: {train_epoch_metrics['accuracy']}\")\n",
    "    return optimizer, train_epoch_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, test_ds):\n",
    "    \"\"\" model / params ?????\"\"\"\n",
    "    metrics = eval_step(model, test_ds)\n",
    "    metrics = jax.device_get(metrics)\n",
    "    eval_summary = jax.tree_map(lambda x: x.item(), metrics)\n",
    "    return eval_summary['loss'], eval_summary['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds = get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "rng, init_rng = jax.random.split(rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = get_initial_params(init_rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "beta = 0.9\n",
    "num_epochs = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = get_optimizer(params, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - epoch: 1, loss: 0.1260634958744049, accuracy: 0.9616333246231079\n",
      "Testing - epoch: 1, loss: 0.050780244171619415, accuracy: 0.9829999804496765\n",
      "Training - epoch: 2, loss: 0.04492035135626793, accuracy: 0.9859166741371155\n",
      "Testing - epoch: 2, loss: 0.03572174161672592, accuracy: 0.988099992275238\n",
      "Training - epoch: 3, loss: 0.030871640890836716, accuracy: 0.9904666543006897\n",
      "Testing - epoch: 3, loss: 0.02965500019490719, accuracy: 0.9889999628067017\n",
      "Training - epoch: 4, loss: 0.0235484316945076, accuracy: 0.9924666881561279\n",
      "Testing - epoch: 4, loss: 0.02583594061434269, accuracy: 0.9918999671936035\n",
      "Training - epoch: 5, loss: 0.01658724993467331, accuracy: 0.9947166442871094\n",
      "Testing - epoch: 5, loss: 0.031633954495191574, accuracy: 0.9907999634742737\n",
      "Training - epoch: 6, loss: 0.01394949946552515, accuracy: 0.9955833554267883\n",
      "Testing - epoch: 6, loss: 0.03818190097808838, accuracy: 0.9888999462127686\n",
      "Training - epoch: 7, loss: 0.010369012132287025, accuracy: 0.9966333508491516\n",
      "Testing - epoch: 7, loss: 0.03041226975619793, accuracy: 0.9912999868392944\n",
      "Training - epoch: 8, loss: 0.009344744496047497, accuracy: 0.9968166947364807\n",
      "Testing - epoch: 8, loss: 0.03692004457116127, accuracy: 0.988099992275238\n",
      "Training - epoch: 9, loss: 0.007275506388396025, accuracy: 0.9976000189781189\n",
      "Testing - epoch: 9, loss: 0.03822000324726105, accuracy: 0.9902999997138977\n",
      "Training - epoch: 10, loss: 0.00675286864861846, accuracy: 0.9978833198547363\n",
      "Testing - epoch: 10, loss: 0.038108158856630325, accuracy: 0.9902999997138977\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "    rng, input_rng = jax.random.split(rng)\n",
    "    optimizer, train_metrics = train_epoch(optimizer, train_ds, batch_size, epoch, input_rng)\n",
    "    test_loss, test_accuracy = eval_model(optimizer.target, test_ds)\n",
    "    print(f\"Testing - epoch: {epoch}, loss: {test_loss}, accuracy: {test_accuracy}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch on Cloud TPUs",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKLajLqUni6H"
      },
      "source": [
        "## Train Your PyTorch Model on Cloud TPU\n",
        "\n",
        "This notebook will show you how to:\n",
        "\n",
        "* Install PyTorch/XLA on Colab, which lets you use PyTorch with TPUs.\n",
        "* Outlines the syntactical elements use specific to TPUs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3rCVMRazoeB"
      },
      "source": [
        "<h3>  &nbsp;&nbsp;Use Colab Cloud TPU&nbsp;&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a></h3>\n",
        "\n",
        "* On the main menu, click Runtime and select **Change runtime type**. Set \"TPU\" as the hardware accelerator.\n",
        "* The cell below makes sure you have access to a TPU on Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P6b3uqfzpDI"
      },
      "source": [
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHzziBW5AoZH"
      },
      "source": [
        "## Installing PyTorch/XLA\n",
        "\n",
        "Run the following cell (or copy it into your own notebook!) to install PyTorch, Torchvision, and PyTorch/XLA. It will take a couple minutes to run.\n",
        "\n",
        "The PyTorch/XLA package lets PyTorch connect to Cloud TPUs. (It's named PyTorch/XLA, not PyTorch/TPU, because XLA is the name of the TPU compiler.) In particular, PyTorch/XLA makes TPU cores available as PyTorch devices. This lets PyTorch create and manipulate tensors on TPUs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUB12htcqU9W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d36b2298-ecef-4391-b023-b0bb3989592b"
      },
      "source": [
        "\n",
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.7-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cloud-tpu-client==0.10 in /usr/local/lib/python3.6/dist-packages (0.10)\n",
            "Requirement already satisfied: torch-xla==1.7 from https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.7-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (1.7)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.6/dist-packages (from cloud-tpu-client==0.10) (4.1.3)\n",
            "Requirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.6/dist-packages (from cloud-tpu-client==0.10) (1.8.0)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client==0.10) (1.15.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.4.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client==0.10) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.2.8)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.17.4)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.16.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.17.2)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.1)\n",
            "Requirement already satisfied: setuptools>=34.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (50.3.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2018.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.52.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.12.4)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVMyz3Z7aCkf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdd3ec4a-c0b8-4a72-f20a-e12071e25c4b"
      },
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# PyTorch/XLA Library Elements\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.debug.metrics as met"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Waiting for TPU to be start up with version pytorch-1.7...\n",
            "WARNING:root:Waiting for TPU to be start up with version pytorch-1.7...\n",
            "WARNING:root:TPU has started up successfully with version pytorch-1.7\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEvu8xq_aEUI"
      },
      "source": [
        "# Model\n",
        "class ToyModel (nn.Module):\n",
        "    \"\"\" Toy Classifier \"\"\"\n",
        "    def __init__(self):\n",
        "        super(ToyModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, 5)\n",
        "        self.mp1 = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(1440, 10)\n",
        "        self.fc2 = nn.Linear(10,10)\n",
        "        self.signature = 0\n",
        "        self.alpha = 0.9\n",
        "        self.gamma = 0.6\n",
        "\n",
        "    def forward(self, x):\n",
        "        signature = torch.diag(x.sum(dim=(0,1)))\n",
        "        running_avg = (self.alpha) * self.signature + (1 - self.alpha) * signature\n",
        "        if torch.rand(1,1) > self.gamma:\n",
        "          self.signature = running_avg      \n",
        "        x = nn.ReLU()(self.conv1(x))\n",
        "        x = self.mp1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        if (self.signature >=  running_avg).all():\n",
        "          x = self.fc2(x)\n",
        "        x = nn.Softmax(dim=-1)(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e0B1CH7aWbu"
      },
      "source": [
        "# Config Parameters\n",
        "FLAGS = {\n",
        "    'batch_size': 32,\n",
        "    'world_size': 1,\n",
        "    'epochs': 1,\n",
        "    'log_steps': 10,\n",
        "    'metrics_debug': True,\n",
        "    'updates_per_epoch' : 400\n",
        "}\n",
        "SERIAL_EXEC = xmp.MpSerialExecutor()\n",
        "WRAPPED_MODEL = xmp.MpModelWrapper(ToyModel())"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_c0S0kJacid"
      },
      "source": [
        "# Training Loop\n",
        "def train(rank, FLAGS):\n",
        "    print(\"Starting train method on rank: {}\".format(rank))\n",
        "    device = xm.xla_device()\n",
        "    model = WRAPPED_MODEL.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), 1e-4)\n",
        "\n",
        "    def get_dataset():\n",
        "        transform = transforms.Compose(\n",
        "            [\n",
        "                torchvision.transforms.ToTensor(),\n",
        "                torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
        "            ]\n",
        "        )\n",
        "       \n",
        "        return torchvision.datasets.MNIST( \n",
        "                '/tmp/', train=True, download=True, transform=transform)\n",
        "\n",
        "    train_dataset = SERIAL_EXEC.run(get_dataset)    \n",
        "\n",
        "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        train_dataset, num_replicas=FLAGS['world_size'], rank=rank)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=FLAGS['batch_size'], shuffle=False,\n",
        "        num_workers=0, sampler=train_sampler)\n",
        "    # PyTorch/XLA: Parallel Loader Wrapper\n",
        "    train_loader = pl.MpDeviceLoader(train_loader, device)\n",
        "\n",
        "    for epoch in range(FLAGS['epochs']):\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            if i > FLAGS['updates_per_epoch']:\n",
        "              break\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            # PyTorch/XLA: All Reduce followed by parameter update \n",
        "            xm.optimizer_step(optimizer)\n",
        "\n",
        "            if not i % FLAGS['log_steps']:\n",
        "                xm.master_print(\n",
        "                    'Epoch: {}/{}, Loss:{}'.format(\n",
        "                        epoch + 1, FLAGS['epochs'], loss.item()\n",
        "                    )\n",
        "                )\n",
        "        if FLAGS['metrics_debug']:\n",
        "            xm.master_print(met.metrics_report())"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmYQ2gNkaiTa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d0eec33-014b-4111-fde3-20e774f4e87a"
      },
      "source": [
        "#PyTorch/XLA: Distributed training on 4 TPU Chips (8 cores)\n",
        "xmp.spawn(train, nprocs=FLAGS['world_size'], args=(FLAGS,), start_method='fork')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting train method on rank: 0\n",
            "Epoch: 1/1, Loss:2.296401262283325\n",
            "Epoch: 1/1, Loss:2.303727865219116\n",
            "Epoch: 1/1, Loss:2.303886651992798\n",
            "Epoch: 1/1, Loss:2.29716420173645\n",
            "Epoch: 1/1, Loss:2.3109562397003174\n",
            "Epoch: 1/1, Loss:2.3045196533203125\n",
            "Epoch: 1/1, Loss:2.3091044425964355\n",
            "Epoch: 1/1, Loss:2.3111164569854736\n",
            "Epoch: 1/1, Loss:2.301154375076294\n",
            "Epoch: 1/1, Loss:2.309042453765869\n",
            "Epoch: 1/1, Loss:2.3037362098693848\n",
            "Epoch: 1/1, Loss:2.312577486038208\n",
            "Epoch: 1/1, Loss:2.303760051727295\n",
            "Epoch: 1/1, Loss:2.3086535930633545\n",
            "Epoch: 1/1, Loss:2.304323434829712\n",
            "Epoch: 1/1, Loss:2.3025269508361816\n",
            "Epoch: 1/1, Loss:2.306070566177368\n",
            "Epoch: 1/1, Loss:2.300405979156494\n",
            "Epoch: 1/1, Loss:2.304892063140869\n",
            "Epoch: 1/1, Loss:2.3042471408843994\n",
            "Epoch: 1/1, Loss:2.2931175231933594\n",
            "Epoch: 1/1, Loss:2.2969605922698975\n",
            "Epoch: 1/1, Loss:2.313149929046631\n",
            "Epoch: 1/1, Loss:2.3150060176849365\n",
            "Epoch: 1/1, Loss:2.3060569763183594\n",
            "Epoch: 1/1, Loss:2.30214786529541\n",
            "Epoch: 1/1, Loss:2.3089547157287598\n",
            "Epoch: 1/1, Loss:2.2922258377075195\n",
            "Epoch: 1/1, Loss:2.2984566688537598\n",
            "Epoch: 1/1, Loss:2.3099312782287598\n",
            "Epoch: 1/1, Loss:2.299004077911377\n",
            "Epoch: 1/1, Loss:2.3138904571533203\n",
            "Epoch: 1/1, Loss:2.3016655445098877\n",
            "Epoch: 1/1, Loss:2.308046579360962\n",
            "Epoch: 1/1, Loss:2.2981061935424805\n",
            "Epoch: 1/1, Loss:2.303898811340332\n",
            "Epoch: 1/1, Loss:2.3060505390167236\n",
            "Epoch: 1/1, Loss:2.300949811935425\n",
            "Epoch: 1/1, Loss:2.307131767272949\n",
            "Epoch: 1/1, Loss:2.3077313899993896\n",
            "Epoch: 1/1, Loss:2.307896614074707\n",
            "Metric: CompileTime\n",
            "  TotalSamples: 9\n",
            "  Accumulator: 02s227ms289.115us\n",
            "  ValueRate: 888ms902.988us / second\n",
            "  Rate: 3.58783 / second\n",
            "  Percentiles: 1%=031ms874.013us; 5%=031ms874.013us; 10%=031ms874.013us; 20%=083ms914.838us; 50%=281ms384.510us; 80%=448ms754.276us; 90%=465ms381.968us; 95%=465ms381.968us; 99%=465ms381.968us\n",
            "Metric: DeviceLockWait\n",
            "  TotalSamples: 844\n",
            "  Accumulator: 924ms981.637us\n",
            "  ValueRate: 142ms613.352us / second\n",
            "  Rate: 129.355 / second\n",
            "  Percentiles: 1%=001.005us; 5%=001.092us; 10%=001.147us; 20%=001.225us; 50%=001.831us; 80%=002ms880.234us; 90%=002ms181.879us; 95%=002ms436.521us; 99%=006ms251.788us\n",
            "Metric: ExecuteTime\n",
            "  TotalSamples: 843\n",
            "  Accumulator: 03s730ms768.697us\n",
            "  ValueRate: 421ms959.390us / second\n",
            "  Rate: 130 / second\n",
            "  Percentiles: 1%=002ms689.520us; 5%=002ms898.881us; 10%=002ms043.391us; 20%=002ms266.474us; 50%=003ms687.388us; 80%=003ms277.807us; 90%=005ms607.824us; 95%=005ms155.946us; 99%=023ms566.806us\n",
            "Metric: InboundData\n",
            "  TotalSamples: 442\n",
            "  Accumulator: 565.00B\n",
            "  ValueRate: 89.06B / second\n",
            "  Rate: 69.6683 / second\n",
            "  Percentiles: 1%=1.00B; 5%=1.00B; 10%=1.00B; 20%=1.00B; 50%=1.00B; 80%=1.00B; 90%=1.00B; 95%=4.00B; 99%=4.00B\n",
            "Metric: InputOutputAliasCount\n",
            "  TotalSamples: 9\n",
            "  Accumulator: 55.00\n",
            "  ValueRate: 24.69 / second\n",
            "  Rate: 4.03946 / second\n",
            "  Percentiles: 1%=1.00; 5%=1.00; 10%=1.00; 20%=1.00; 50%=1.00; 80%=15.00; 90%=15.00; 95%=15.00; 99%=15.00\n",
            "Metric: IrValueTensorToXlaData\n",
            "  TotalSamples: 6\n",
            "  Accumulator: 027ms642.299us\n",
            "  ValueRate: 01s178ms540.035us / second\n",
            "  Rate: 265.189 / second\n",
            "  Percentiles: 1%=002ms947.127us; 5%=002ms947.127us; 10%=002ms947.127us; 20%=002ms048.497us; 50%=005ms726.393us; 80%=005ms352.011us; 90%=009ms641.372us; 95%=009ms641.372us; 99%=009ms641.372us\n",
            "Metric: OutboundData\n",
            "  TotalSamples: 111\n",
            "  Accumulator: 39.20MB\n",
            "  ValueRate: 900.40KB / second\n",
            "  Rate: 2.48966 / second\n",
            "  Percentiles: 1%=4.00B; 5%=40.00B; 10%=393.00KB; 20%=393.00KB; 50%=393.00KB; 80%=393.00KB; 90%=393.00KB; 95%=393.00KB; 99%=393.00KB\n",
            "Metric: ReleaseDataHandlesTime\n",
            "  TotalSamples: 3018\n",
            "  Accumulator: 03s624ms692.266us\n",
            "  ValueRate: 680ms979.237us / second\n",
            "  Rate: 839.555 / second\n",
            "  Percentiles: 1%=499.175us; 5%=553.809us; 10%=593.995us; 20%=641.189us; 50%=750.283us; 80%=872.206us; 90%=959.987us; 95%=001ms125.773us; 99%=003ms603.184us\n",
            "Metric: TensorsGraphSize\n",
            "  TotalSamples: 844\n",
            "  Accumulator: 45622.00\n",
            "  ValueRate: 7026.09 / second\n",
            "  Rate: 129.982 / second\n",
            "  Percentiles: 1%=14.00; 5%=14.00; 10%=14.00; 20%=14.00; 50%=15.00; 80%=86.00; 90%=115.00; 95%=115.00; 99%=115.00\n",
            "Metric: TransferFromServerTime\n",
            "  TotalSamples: 442\n",
            "  Accumulator: 657ms046.182us\n",
            "  ValueRate: 104ms564.108us / second\n",
            "  Rate: 69.6684 / second\n",
            "  Percentiles: 1%=001ms002.426us; 5%=001ms080.346us; 10%=001ms136.333us; 20%=001ms239.285us; 50%=001ms426.450us; 80%=002ms656.338us; 90%=002ms786.757us; 95%=002ms952.131us; 99%=004ms991.734us\n",
            "Metric: TransferToServerTime\n",
            "  TotalSamples: 111\n",
            "  Accumulator: 825ms246.616us\n",
            "  ValueRate: 019ms509.542us / second\n",
            "  Rate: 2.48963 / second\n",
            "  Percentiles: 1%=002ms043.704us; 5%=005ms582.035us; 10%=007ms936.034us; 20%=007ms280.801us; 50%=008ms596.380us; 80%=008ms913.059us; 90%=008ms112.944us; 95%=008ms294.149us; 99%=009ms607.708us\n",
            "Metric: TransferToServerTransformTime\n",
            "  TotalSamples: 111\n",
            "  Accumulator: 040ms188.441us\n",
            "  ValueRate: 901.402us / second\n",
            "  Rate: 2.48966 / second\n",
            "  Percentiles: 1%=167.896us; 5%=220.737us; 10%=279.974us; 20%=296.535us; 50%=345.134us; 80%=383.715us; 90%=406.440us; 95%=453.148us; 99%=001ms276.443us\n",
            "Counter: CachedCompile\n",
            "  Value: 835\n",
            "Counter: CreateCompileHandles\n",
            "  Value: 9\n",
            "Counter: CreateDataHandles\n",
            "  Value: 7040\n",
            "Counter: CreateXlaTensor\n",
            "  Value: 17167\n",
            "Counter: DestroyDataHandles\n",
            "  Value: 7014\n",
            "Counter: DestroyXlaTensor\n",
            "  Value: 17138\n",
            "Counter: DeviceDataCacheMiss\n",
            "  Value: 3\n",
            "Counter: MarkStep\n",
            "  Value: 402\n",
            "Counter: ReleaseDataHandles\n",
            "  Value: 7014\n",
            "Counter: UncachedCompile\n",
            "  Value: 9\n",
            "Counter: XRTAllocateFromTensor_Empty\n",
            "  Value: 13\n",
            "Counter: XrtCompile_Empty\n",
            "  Value: 128\n",
            "Counter: XrtExecuteChained_Empty\n",
            "  Value: 128\n",
            "Counter: XrtExecute_Empty\n",
            "  Value: 128\n",
            "Counter: XrtMemoryInfo_Empty\n",
            "  Value: 128\n",
            "Counter: XrtRead_Empty\n",
            "  Value: 128\n",
            "Counter: XrtReleaseAllocationHandle_Empty\n",
            "  Value: 128\n",
            "Counter: XrtReleaseCompileHandle_Empty\n",
            "  Value: 128\n",
            "Counter: XrtSessionCount\n",
            "  Value: 9\n",
            "Counter: XrtSubTuple_Empty\n",
            "  Value: 128\n",
            "Counter: aten::_local_scalar_dense\n",
            "  Value: 442\n",
            "Counter: xla::_copy_from\n",
            "  Value: 6\n",
            "Counter: xla::_log_softmax\n",
            "  Value: 401\n",
            "Counter: xla::_log_softmax_backward_data\n",
            "  Value: 401\n",
            "Counter: xla::_softmax\n",
            "  Value: 401\n",
            "Counter: xla::_softmax_backward_data\n",
            "  Value: 401\n",
            "Counter: xla::add\n",
            "  Value: 401\n",
            "Counter: xla::add_\n",
            "  Value: 4338\n",
            "Counter: xla::addmm\n",
            "  Value: 568\n",
            "Counter: xla::all\n",
            "  Value: 401\n",
            "Counter: xla::as_strided\n",
            "  Value: 6\n",
            "Counter: xla::convolution_backward_overrideable\n",
            "  Value: 401\n",
            "Counter: xla::convolution_overrideable\n",
            "  Value: 401\n",
            "Counter: xla::diag\n",
            "  Value: 401\n",
            "Counter: xla::empty\n",
            "  Value: 407\n",
            "Counter: xla::empty_strided\n",
            "  Value: 6\n",
            "Counter: xla::fill_\n",
            "  Value: 401\n",
            "Counter: xla::ge\n",
            "  Value: 401\n",
            "Counter: xla::max_pool2d\n",
            "  Value: 401\n",
            "Counter: xla::mm\n",
            "  Value: 1136\n",
            "Counter: xla::mul\n",
            "  Value: 801\n",
            "Counter: xla::nll_loss_backward\n",
            "  Value: 401\n",
            "Counter: xla::nll_loss_forward\n",
            "  Value: 401\n",
            "Counter: xla::relu\n",
            "  Value: 401\n",
            "Counter: xla::sum\n",
            "  Value: 969\n",
            "Counter: xla::t\n",
            "  Value: 2272\n",
            "Counter: xla::threshold_backward\n",
            "  Value: 401\n",
            "Counter: xla::view\n",
            "  Value: 1370\n",
            "Counter: xla::zero_\n",
            "  Value: 2400\n",
            "Metric: XrtAllocateFromTensor\n",
            "  TotalSamples: 825\n",
            "  Accumulator: 01s228ms319.527us\n",
            "  Mean: 001ms488.872us\n",
            "  StdDev: 373.535us\n",
            "  Rate: 18.5053 / second\n",
            "  Percentiles: 25%=001ms317.791us; 50%=002ms527.136us; 80%=002ms739.945us; 90%=002ms868.939us; 95%=002ms017.585us; 99%=002ms275.610us\n",
            "Metric: XrtCompile\n",
            "  TotalSamples: 9\n",
            "  Accumulator: 02s185ms121.012us\n",
            "  Mean: 243ms791.224us\n",
            "  StdDev: 166ms969.265us\n",
            "  Rate: 3.58831 / second\n",
            "  Percentiles: 25%=089ms840.711us; 50%=279ms143.213us; 80%=445ms366.874us; 90%=460ms386.160us; 95%=460ms386.160us; 99%=460ms386.160us\n",
            "Metric: XrtExecute\n",
            "  TotalSamples: 844\n",
            "  Accumulator: 01s323ms935.566us\n",
            "  Mean: 002ms567.459us\n",
            "  StdDev: 454.352us\n",
            "  Rate: 130.056 / second\n",
            "  Percentiles: 25%=001ms249.311us; 50%=002ms543.466us; 80%=002ms930.501us; 90%=002ms186.489us; 95%=002ms352.321us; 99%=003ms658.770us\n",
            "Metric: XrtExecutorEvict\n",
            "  TotalSamples: 0\n",
            "  Accumulator: nanB\n",
            "  Mean: nanB\n",
            "  StdDev: nanB\n",
            "  Percentiles: \n",
            "Metric: XrtReadLiteral\n",
            "  TotalSamples: 442\n",
            "  Accumulator: 219ms043.255us\n",
            "  Mean: 495.573us\n",
            "  StdDev: 131.636us\n",
            "  Rate: 69.6701 / second\n",
            "  Percentiles: 25%=403.193us; 50%=478.580us; 80%=584.937us; 90%=665.707us; 95%=768.191us; 99%=890.888us\n",
            "Metric: XrtReleaseAllocation\n",
            "  TotalSamples: 3019\n",
            "  Accumulator: 108ms961.946us\n",
            "  Mean: 037.604us\n",
            "  StdDev: 049.172us\n",
            "  Rate: 839.5 / second\n",
            "  Percentiles: 25%=014.614us; 50%=023.102us; 80%=046.009us; 90%=078.575us; 95%=125.119us; 99%=254.385us\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYIKITU2HUIf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
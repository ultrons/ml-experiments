{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch on Cloud TPUs",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKLajLqUni6H"
      },
      "source": [
        "## Train Your PyTorch Model on Cloud TPU\n",
        "\n",
        "This notebook will show you how to:\n",
        "\n",
        "* Install PyTorch/XLA on Colab, which lets you use PyTorch with TPUs.\n",
        "* Outlines the syntactical elements use specific to TPUs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3rCVMRazoeB"
      },
      "source": [
        "<h3>  &nbsp;&nbsp;Use Colab Cloud TPU&nbsp;&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a></h3>\n",
        "\n",
        "* On the main menu, click Runtime and select **Change runtime type**. Set \"TPU\" as the hardware accelerator.\n",
        "* The cell below makes sure you have access to a TPU on Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P6b3uqfzpDI"
      },
      "source": [
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHzziBW5AoZH"
      },
      "source": [
        "## Installing PyTorch/XLA\n",
        "\n",
        "Run the following cell (or copy it into your own notebook!) to install PyTorch, Torchvision, and PyTorch/XLA. It will take a couple minutes to run.\n",
        "\n",
        "The PyTorch/XLA package lets PyTorch connect to Cloud TPUs. (It's named PyTorch/XLA, not PyTorch/TPU, because XLA is the name of the TPU compiler.) In particular, PyTorch/XLA makes TPU cores available as PyTorch devices. This lets PyTorch create and manipulate tensors on TPUs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUB12htcqU9W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "469313cb-6ffb-4168-842b-dff6347bc6b9"
      },
      "source": [
        "\n",
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.7-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cloud-tpu-client==0.10 in /usr/local/lib/python3.6/dist-packages (0.10)\n",
            "Requirement already satisfied: torch-xla==1.7 from https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.7-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (1.7)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.6/dist-packages (from cloud-tpu-client==0.10) (4.1.3)\n",
            "Requirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.6/dist-packages (from cloud-tpu-client==0.10) (1.8.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.2.8)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.17.4)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client==0.10) (4.6)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client==0.10) (1.15.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.4.8)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.0.4)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.16.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.17.2)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2018.9)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=34.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (50.3.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.52.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.12.4)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVMyz3Z7aCkf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec5b078a-d28b-4dbd-d37d-1380414f86df"
      },
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# PyTorch/XLA Library Elements\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.debug.metrics as met"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:TPU has started up successfully with version pytorch-1.7\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEvu8xq_aEUI"
      },
      "source": [
        "# Model\n",
        "class ToyModel(nn.Module):\n",
        "    \"\"\" Toy Classifier \"\"\"\n",
        "    def __init__(self):\n",
        "        super(ToyModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, 5)\n",
        "        self.mp1 = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(1440, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.ReLU()(self.conv1(x))\n",
        "        x = self.mp1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = nn.Softmax(dim=-1)(x)\n",
        "        return x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e0B1CH7aWbu"
      },
      "source": [
        "# Config Parameters\n",
        "FLAGS = {\n",
        "    'batch_size': 32,\n",
        "    'world_size': 1,\n",
        "    'epochs': 1,\n",
        "    'log_steps': 10,\n",
        "    'metrics_debug': False,\n",
        "    'updates_per_epoch' : 400\n",
        "}\n",
        "SERIAL_EXEC = xmp.MpSerialExecutor()\n",
        "WRAPPED_MODEL = xmp.MpModelWrapper(ToyModel())"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_c0S0kJacid"
      },
      "source": [
        "# Training Loop\n",
        "def train(rank, FLAGS):\n",
        "    print(\"Starting train method on rank: {}\".format(rank))\n",
        "    device = xm.xla_device()\n",
        "    model = WRAPPED_MODEL.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), 1e-4)\n",
        "\n",
        "    def get_dataset():\n",
        "        transform = transforms.Compose(\n",
        "            [\n",
        "                torchvision.transforms.ToTensor(),\n",
        "                torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
        "            ]\n",
        "        )\n",
        "       \n",
        "        return torchvision.datasets.MNIST( \n",
        "                '/tmp/', train=True, download=True, transform=transform)\n",
        "\n",
        "    train_dataset = SERIAL_EXEC.run(get_dataset)    \n",
        "\n",
        "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        train_dataset, num_replicas=FLAGS['world_size'], rank=rank)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=FLAGS['batch_size'], shuffle=False,\n",
        "        num_workers=0, sampler=train_sampler)\n",
        "    # PyTorch/XLA: Parallel Loader Wrapper\n",
        "    train_loader = pl.MpDeviceLoader(train_loader, device)\n",
        "\n",
        "    for epoch in range(FLAGS['epochs']):\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            if i > FLAGS['updates_per_epoch']:\n",
        "              break\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            # PyTorch/XLA: All Reduce followed by parameter update \n",
        "            xm.optimizer_step(optimizer)\n",
        "\n",
        "            if not i % FLAGS['log_steps']:\n",
        "                xm.master_print(\n",
        "                    'Epoch: {}/{}, Loss:{}'.format(\n",
        "                        epoch + 1, FLAGS['epochs'], loss.item()\n",
        "                    )\n",
        "                )\n",
        "        if FLAGS['metrics_debug']:\n",
        "            xm.master_print(met.metrics_report())"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmYQ2gNkaiTa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15c341a8-e9aa-40e8-e42a-d2ff65552384"
      },
      "source": [
        "#PyTorch/XLA: Distributed training on 4 TPU Chips (8 cores)\n",
        "xmp.spawn(train, nprocs=FLAGS['world_size'], args=(FLAGS,), start_method='fork')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting train method on rank: 0\n",
            "Epoch: 1/1, Loss:2.296616315841675\n",
            "Epoch: 1/1, Loss:2.299046754837036\n",
            "Epoch: 1/1, Loss:2.29319429397583\n",
            "Epoch: 1/1, Loss:2.2989964485168457\n",
            "Epoch: 1/1, Loss:2.2943575382232666\n",
            "Epoch: 1/1, Loss:2.2907660007476807\n",
            "Epoch: 1/1, Loss:2.284073829650879\n",
            "Epoch: 1/1, Loss:2.284733772277832\n",
            "Epoch: 1/1, Loss:2.2944512367248535\n",
            "Epoch: 1/1, Loss:2.2889037132263184\n",
            "Epoch: 1/1, Loss:2.302015542984009\n",
            "Epoch: 1/1, Loss:2.2987492084503174\n",
            "Epoch: 1/1, Loss:2.2814888954162598\n",
            "Epoch: 1/1, Loss:2.2919561862945557\n",
            "Epoch: 1/1, Loss:2.300222873687744\n",
            "Epoch: 1/1, Loss:2.2973620891571045\n",
            "Epoch: 1/1, Loss:2.287539005279541\n",
            "Epoch: 1/1, Loss:2.295802593231201\n",
            "Epoch: 1/1, Loss:2.2876291275024414\n",
            "Epoch: 1/1, Loss:2.2938716411590576\n",
            "Epoch: 1/1, Loss:2.3000991344451904\n",
            "Epoch: 1/1, Loss:2.2910425662994385\n",
            "Epoch: 1/1, Loss:2.2864394187927246\n",
            "Epoch: 1/1, Loss:2.284902572631836\n",
            "Epoch: 1/1, Loss:2.270642042160034\n",
            "Epoch: 1/1, Loss:2.2965376377105713\n",
            "Epoch: 1/1, Loss:2.304417371749878\n",
            "Epoch: 1/1, Loss:2.302474021911621\n",
            "Epoch: 1/1, Loss:2.310530662536621\n",
            "Epoch: 1/1, Loss:2.2839159965515137\n",
            "Epoch: 1/1, Loss:2.2952780723571777\n",
            "Epoch: 1/1, Loss:2.2826762199401855\n",
            "Epoch: 1/1, Loss:2.2912559509277344\n",
            "Epoch: 1/1, Loss:2.2923243045806885\n",
            "Epoch: 1/1, Loss:2.2986843585968018\n",
            "Epoch: 1/1, Loss:2.2928972244262695\n",
            "Epoch: 1/1, Loss:2.2917392253875732\n",
            "Epoch: 1/1, Loss:2.3000595569610596\n",
            "Epoch: 1/1, Loss:2.2889580726623535\n",
            "Epoch: 1/1, Loss:2.2901248931884766\n",
            "Epoch: 1/1, Loss:2.3025403022766113\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYIKITU2HUIf"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}
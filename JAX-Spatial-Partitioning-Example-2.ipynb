{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddd3d89d",
   "metadata": {},
   "source": [
    "# Annotated MNIST Example Augmented\n",
    "\n",
    "This notebook is based on [Annotated MNIST](https://colab.sandbox.google.com/github/google/flax/blob/main/docs/getting_started.ipynb#scrollTo=KvuEA8Tw-MYa) example from [FLAX](https://github.com/google/flax)\n",
    "\n",
    "The primary objective is to illustrate spatial partitioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e73a851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 23:26:56.766944: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2022-10-30 23:26:57.455152: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2022-10-30 23:26:57.455242: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2022-10-30 23:26:57.455248: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp                # JAX NumPy\n",
    "\n",
    "from flax import linen as nn           # The Linen API\n",
    "from flax.training import train_state  # Useful dataclass to keep train state\n",
    "\n",
    "import numpy as np                     # Ordinary NumPy\n",
    "import optax                           # Optimizers\n",
    "import tensorflow_datasets as tfds     # TFDS for MNIST\n",
    "\n",
    "import os\n",
    "os.environ['FLAX_PROFILE'] = '1'\n",
    "server = jax.profiler.start_server(1234)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c466944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets():\n",
    "    ds_builder = tfds.builder('fashion_mnist')\n",
    "    ds_builder.download_and_prepare()\n",
    "    train_ds = tfds.as_numpy(ds_builder.as_dataset(split='train', batch_size=-1))\n",
    "    test_ds = tfds.as_numpy(ds_builder.as_dataset(split='test', batch_size=-1))\n",
    "    train_ds['image'] = jnp.float32(train_ds['image']) / 255.\n",
    "    test_ds['image'] = jnp.float32(test_ds['image']) / 255.\n",
    "    return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9ba20f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \"\"\"A simple CNN model.\"\"\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = x.reshape((x.shape[0], -1))  # flatten\n",
    "        x = nn.Dense(features=256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=10)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e499d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(*, logits, labels):\n",
    "    labels_onehot = jax.nn.one_hot(labels, num_classes=10)\n",
    "    return optax.softmax_cross_entropy(logits=logits, labels=labels_onehot).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29d62ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(*, logits, labels):\n",
    "    loss = cross_entropy_loss(logits=logits, labels=labels)\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
    "    return {'loss': loss, 'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ceeac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(rng, learning_rate, momentum):\n",
    "    cnn = CNN()\n",
    "    params = cnn.init(rng, jnp.ones([1, 28, 28, 1]))['params']\n",
    "    tx = optax.sgd(learning_rate, momentum)\n",
    "    return train_state.TrainState.create(\n",
    "        apply_fn=cnn.apply, params=params, tx=tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eba12f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    def loss_fn(params):\n",
    "        logits = CNN().apply({'params': params}, batch['image'])\n",
    "        loss = cross_entropy_loss(logits=logits, labels=batch['label'])\n",
    "        return loss, logits\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (_, logits), grads = grad_fn(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    metrics = compute_metrics(logits=logits, labels=batch['label'])\n",
    "    return state, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "446c35bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def eval_step(params, eval_ds):\n",
    "    logits = CNN().apply({'params': params}, eval_ds['image'])\n",
    "    return compute_metrics(logits=logits, labels=eval_ds['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac025ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(state, train_ds, batch_size, epoch, rng):\n",
    "    train_ds_size = len(train_ds['image'])\n",
    "    steps_per_epoch = train_ds_size // batch_size\n",
    "    \n",
    "    perms = jax.random.permutation(rng, train_ds_size)\n",
    "    perms = perms[:steps_per_epoch * batch_size]\n",
    "    perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "    batch_metrics = []\n",
    "    for perm in perms:\n",
    "        batch = {k: v[perm, ...] for k, v in train_ds.items()}\n",
    "        state, metrics = train_step(state, batch)\n",
    "        batch_metrics.append(metrics)\n",
    "    batch_metrics_np = jax.device_get(batch_metrics)\n",
    "    epoch_metrics_np = {\n",
    "        k: np.mean([metrics[k] for metrics in batch_metrics_np])\n",
    "        for k in batch_metrics_np[0]\n",
    "    }\n",
    "    print(f\"train epoch: {epoch}, loss: {epoch_metrics_np['loss']}, accuracy: {epoch_metrics_np['accuracy'] * 100}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51808b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(params, test_ds):\n",
    "    metrics = eval_step(params, test_ds)\n",
    "    metrics = jax.device_get(metrics)\n",
    "    summary = jax.tree_util.tree_map(lambda x: x.item(), metrics)\n",
    "    return summary['loss'], summary['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ff212d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 23:27:01.923139: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2022-10-30 23:27:01.923179: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_ds = get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "337fd21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "rng, init_rng = jax.random.split(rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb38fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adfaaef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = create_train_state(init_rng, learning_rate, momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa0e9db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "batch_size = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ee325e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 1178992640 bytes == 0x14d87c000 @  0x7f7c91209680 0x7f7c9122a824 0x7f7aeea420da 0x7f7aec45d4e0 0x7f7aec45d459 0x7f7aec2e1d38 0x7f7aec2e1c39 0x7f7aeb54e908 0x7f7aeb57eacb 0x7f7aebf1ce75 0x7f7aebf1f4b9 0x7f7aee645665 0x7f7aee64a6ab 0x7f7aee6514e5 0x7f7aee86ddbe 0x7f7c90fdd609 0x7f7c91117163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 1, loss: 2.324336290359497, accuracy: 31.84604048728943\n",
      " test epoch: 1, loss: 1.85, accuracy: 46.36\n",
      "train epoch: 2, loss: 1.2135814428329468, accuracy: 59.375\n",
      " test epoch: 2, loss: 0.66, accuracy: 75.51\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "    # Use a separate PRNG key to permute image data during shuffling\n",
    "    rng, input_rng = jax.random.split(rng)\n",
    "    # Run an optimization step over a training batch\n",
    "    if epoch == 1:\n",
    "        jax.profiler.start_trace(log_dir='/home/sivaibhav/profile-log')\n",
    "    state = train_epoch(state, train_ds, batch_size, epoch, input_rng)\n",
    "    if epoch == 2:\n",
    "        jax.profiler.stop_trace()\n",
    "    # Evaluate on the test set after each training epoch\n",
    "    test_loss, test_accuracy = eval_model(state.params, test_ds)\n",
    "    print(' test epoch: %d, loss: %.2f, accuracy: %.2f' % (\n",
    "      epoch, test_loss, test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e7f6555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from jax.experimental import maps\n",
    "from jax.experimental import PartitionSpec\n",
    "from jax.experimental.pjit import pjit\n",
    "import numpy as np\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8940b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mesh(array([[0, 1],\n",
       "       [2, 3]]), ('x', 'y'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh_shape = (2, 2)\n",
    "devices = np.asarray(jax.devices()).reshape(*mesh_shape)\n",
    "mesh = maps.Mesh(devices, ('x', 'y'))\n",
    "mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e372baf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_train_step = pjit(\n",
    "    train_step,\n",
    "    in_axis_resources=(None, \n",
    "                       {'image': PartitionSpec(None, 'x', 'y', None),\n",
    "                        'label': None \n",
    "                       }\n",
    "                      ),\n",
    "    out_axis_resources=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ac545b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_train_epoch(state, train_ds, batch_size, epoch, rng):\n",
    "    train_ds_size = len(train_ds['image'])\n",
    "    steps_per_epoch = train_ds_size // batch_size\n",
    "    \n",
    "    perms = jax.random.permutation(rng, train_ds_size)\n",
    "    perms = perms[:steps_per_epoch * batch_size]\n",
    "    perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "    batch_metrics = []\n",
    "    for perm in perms:\n",
    "        batch = {k: v[perm, ...] for k, v in train_ds.items()}\n",
    "        state, metrics = p_train_step(state, batch)\n",
    "        batch_metrics.append(metrics)\n",
    "    batch_metrics_np = jax.device_get(batch_metrics)\n",
    "    epoch_metrics_np = {\n",
    "        k: np.mean([metrics[k] for metrics in batch_metrics_np])\n",
    "        for k in batch_metrics_np[0]\n",
    "    }\n",
    "    print(f\"train epoch: {epoch}, loss: {epoch_metrics_np['loss']}, accuracy: {epoch_metrics_np['accuracy'] * 100}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28eb1c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_eval_step = pjit(\n",
    "    eval_step,\n",
    "    in_axis_resources=(None, \n",
    "                       {'image': PartitionSpec(None, 'x', 'y', None),\n",
    "                        'label': None \n",
    "                       }\n",
    "                      ),\n",
    "    out_axis_resources=None\n",
    ")\n",
    "def p_eval_model(params, test_ds):\n",
    "    metrics = p_eval_step(params, test_ds)\n",
    "    metrics = jax.device_get(metrics)\n",
    "    summary = jax.tree_util.tree_map(lambda x: x.item(), metrics)\n",
    "    return summary['loss'], summary['accuracy']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99712111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 1, loss: 0.5606998801231384, accuracy: 78.46511602401733\n",
      " test epoch: 1, loss: 0.52, accuracy: 80.20\n",
      "train epoch: 2, loss: 0.46477749943733215, accuracy: 82.48080611228943\n",
      " test epoch: 2, loss: 0.45, accuracy: 83.08\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "    # Use a separate PRNG key to permute image data during shuffling\n",
    "    rng, input_rng = jax.random.split(rng)\n",
    "    # Run an optimization step over a training batch\n",
    "    if epoch == 1:\n",
    "        jax.profiler.start_trace(log_dir='/home/sivaibhav/profile-log')\n",
    "    with maps.Mesh(mesh.devices, mesh.axis_names):\n",
    "        state = p_train_epoch(state, train_ds, batch_size, epoch, input_rng)\n",
    "            # Evaluate on the test set after each training epoch\n",
    "        test_loss, test_accuracy = p_eval_model(state.params, test_ds)\n",
    "        print(' test epoch: %d, loss: %.2f, accuracy: %.2f' % (\n",
    "          epoch, test_loss, test_accuracy * 100))\n",
    "    if epoch == 2:\n",
    "        jax.profiler.stop_trace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fe27a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9711bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d27674c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

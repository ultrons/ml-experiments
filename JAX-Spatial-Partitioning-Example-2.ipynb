{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddd3d89d",
   "metadata": {},
   "source": [
    "# Annotated MNIST Example Augmented\n",
    "\n",
    "This notebook is based on [Annotated MNIST](https://colab.sandbox.google.com/github/google/flax/blob/main/docs/getting_started.ipynb#scrollTo=KvuEA8Tw-MYa) example from [FLAX](https://github.com/google/flax)\n",
    "\n",
    "The primary objective is to illustrate spatial partitioning.\n",
    "\n",
    "We begin with the default example i.e. model without spatial partitioning.\n",
    "And then we illustrate spatial partitioning version with JAX pjit API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e73a851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-02 17:37:46.589625: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2022-11-02 17:37:47.360589: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2022-11-02 17:37:47.360668: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2022-11-02 17:37:47.360674: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp                # JAX NumPy\n",
    "\n",
    "from flax import linen as nn           # The Linen API\n",
    "from flax.training import train_state  # Useful dataclass to keep train state\n",
    "\n",
    "import numpy as np                     # Ordinary NumPy\n",
    "import optax                           # Optimizers\n",
    "import tensorflow_datasets as tfds     # TFDS for MNIST\n",
    "\n",
    "import os\n",
    "\n",
    "# Optional [For profiling only]\n",
    "os.environ['FLAX_PROFILE'] = '1'\n",
    "server = jax.profiler.start_server(1234)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750de130",
   "metadata": {},
   "source": [
    "## Download and prepate dataset from TFDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c466944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets():\n",
    "    ds_builder = tfds.builder('fashion_mnist')\n",
    "    ds_builder.download_and_prepare()\n",
    "    train_ds = tfds.as_numpy(ds_builder.as_dataset(split='train', batch_size=-1))\n",
    "    test_ds = tfds.as_numpy(ds_builder.as_dataset(split='test', batch_size=-1))\n",
    "    train_ds['image'] = jnp.float32(train_ds['image']) / 255.\n",
    "    test_ds['image'] = jnp.float32(test_ds['image']) / 255.\n",
    "    return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69779a4",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9ba20f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \"\"\"A simple CNN model.\"\"\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = x.reshape((x.shape[0], -1))  # flatten\n",
    "        x = nn.Dense(features=256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=10)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95add6e6",
   "metadata": {},
   "source": [
    "### Define cross entropy loss and metrics functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e499d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(*, logits, labels):\n",
    "    labels_onehot = jax.nn.one_hot(labels, num_classes=10)\n",
    "    return optax.softmax_cross_entropy(logits=logits, labels=labels_onehot).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29d62ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(*, logits, labels):\n",
    "    loss = cross_entropy_loss(logits=logits, labels=labels)\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
    "    return {'loss': loss, 'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e647065",
   "metadata": {},
   "source": [
    "### Define the train_step \n",
    "\n",
    "Following is the un-partitioned version of the train_step. \n",
    "It works on a single batch. We create the gradiente of the loss function.\n",
    "And then compute the loss and gradient of loss for the given batch and network state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eba12f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    def loss_fn(params):\n",
    "        logits = CNN().apply({'params': params}, batch['image'])\n",
    "        loss = cross_entropy_loss(logits=logits, labels=batch['label'])\n",
    "        return loss, logits\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (_, logits), grads = grad_fn(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    metrics = compute_metrics(logits=logits, labels=batch['label'])\n",
    "    return state, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93872eda",
   "metadata": {},
   "source": [
    "Evaluation step function, although step is misleading here since we are not working with a batch but the entirity of the eval dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "446c35bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def eval_step(params, eval_ds):\n",
    "    logits = CNN().apply({'params': params}, eval_ds['image'])\n",
    "    return compute_metrics(logits=logits, labels=eval_ds['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3667c4d",
   "metadata": {},
   "source": [
    "Now we are ready to define a train epoch in terms of train_step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac025ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(state, train_ds, batch_size, epoch, rng):\n",
    "    train_ds_size = len(train_ds['image'])\n",
    "    steps_per_epoch = train_ds_size // batch_size\n",
    "    \n",
    "    perms = jax.random.permutation(rng, train_ds_size)\n",
    "    perms = perms[:steps_per_epoch * batch_size]\n",
    "    perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "    batch_metrics = []\n",
    "    for perm in perms:\n",
    "        batch = {k: v[perm, ...] for k, v in train_ds.items()}\n",
    "        state, metrics = train_step(state, batch)\n",
    "        batch_metrics.append(metrics)\n",
    "    batch_metrics_np = jax.device_get(batch_metrics)\n",
    "    epoch_metrics_np = {\n",
    "        k: np.mean([metrics[k] for metrics in batch_metrics_np])\n",
    "        for k in batch_metrics_np[0]\n",
    "    }\n",
    "    print(f\"train epoch: {epoch}, loss: {epoch_metrics_np['loss']}, accuracy: {epoch_metrics_np['accuracy'] * 100}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860c178a",
   "metadata": {},
   "source": [
    "And eval_model in terms of eval_step function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51808b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(params, test_ds):\n",
    "    metrics = eval_step(params, test_ds)\n",
    "    metrics = jax.device_get(metrics)\n",
    "    summary = jax.tree_util.tree_map(lambda x: x.item(), metrics)\n",
    "    return summary['loss'], summary['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6f101c",
   "metadata": {},
   "source": [
    "Create train state, achieves two objectives: \n",
    "1. Initialize the model\n",
    "2. Extract the param tree (train state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ceeac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(rng, learning_rate, momentum):\n",
    "    cnn = CNN()\n",
    "    params = cnn.init(rng, jnp.ones([1, 28, 28, 1]))['params']\n",
    "    tx = optax.sgd(learning_rate, momentum)\n",
    "    return train_state.TrainState.create(\n",
    "        apply_fn=cnn.apply, params=params, tx=tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7699f9d",
   "metadata": {},
   "source": [
    "# Run training (with No Spatial Partioning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ff212d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-02 17:37:52.317168: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2022-11-02 17:37:52.317206: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_ds = get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "337fd21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "rng, init_rng = jax.random.split(rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb38fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adfaaef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = create_train_state(init_rng, learning_rate, momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa0e9db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "batch_size = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ee325e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 1178992640 bytes == 0x14f7ea000 @  0x7f2ecbe00680 0x7f2ecbe21824 0x7f2d296390da 0x7f2d270544e0 0x7f2d27054459 0x7f2d26ed8d38 0x7f2d26ed8c39 0x7f2d26145908 0x7f2d26175acb 0x7f2d26b13e75 0x7f2d26b164b9 0x7f2d2923c665 0x7f2d292416ab 0x7f2d292484e5 0x7f2d29464dbe 0x7f2ecbbd4609 0x7f2ecbd0e163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 1, loss: 2.324336290359497, accuracy: 31.84604048728943\n",
      " test epoch: 1, loss: 1.85, accuracy: 46.36\n",
      "train epoch: 2, loss: 1.2135814428329468, accuracy: 59.375\n",
      " test epoch: 2, loss: 0.66, accuracy: 75.51\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "    # Use a separate PRNG key to permute image data during shuffling\n",
    "    rng, input_rng = jax.random.split(rng)\n",
    "    # Run an optimization step over a training batch\n",
    "    if epoch == 1:\n",
    "        jax.profiler.start_trace(log_dir='/home/sivaibhav/profile-log')\n",
    "    state = train_epoch(state, train_ds, batch_size, epoch, input_rng)\n",
    "    if epoch == 2:\n",
    "        jax.profiler.stop_trace()\n",
    "    # Evaluate on the test set after each training epoch\n",
    "    test_loss, test_accuracy = eval_model(state.params, test_ds)\n",
    "    print(' test epoch: %d, loss: %.2f, accuracy: %.2f' % (\n",
    "      epoch, test_loss, test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c78c67b",
   "metadata": {},
   "source": [
    "# Spatial Partitioning\n",
    "\n",
    "Spatial partioning can be viewed as a special case of data parallelism where we parition input images along the X and Y dimension instead of the batch dimension (seen in common data parallelism).\n",
    "\n",
    "In the following sections we will use JAX PJIT API to express spatial partitioning.\n",
    "PJIT is a general purpose API which allows to express partioning intent for the inputs and outputs of a function.\n",
    "This intent is then automatically propagated through the function graph (using XLA SPMD) to create a partitioned version of the function with almost no manual effort required to update the model. This gives a power way to express a variety of parallelisms including SPMD based tensor and pipeline parallelisms, fully sharded data parallelism and spatial partitioning.\n",
    "For more details on PJIT please refer to [this tutorial].(https://jax.readthedocs.io/en/latest/jax-101/08-pjit.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e7f6555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from jax.experimental import maps\n",
    "from jax.experimental import PartitionSpec\n",
    "from jax.experimental.pjit import pjit\n",
    "import numpy as np\n",
    "import functools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baadb0e1",
   "metadata": {},
   "source": [
    "## Step-1 Define a device mesh\n",
    "The device mesh is a logical view of the physical device array expressed with named axes.\n",
    "These axes will subsequently be referenced to express partitioning intent or annotation.\n",
    "It is important that each of these axis correspond to a physical torus (1-D or 2-D). \n",
    "In the current example we are working with a TPU device i.e. 4 chip configuration.\n",
    "For larger slice shape awareness of [mesh topologies](https://cloud.google.com/tpu/docs/types-topologies) is very critical to construct the optimal device mesh. We recommend using [mesh utils](https://github.com/google/jax/blob/main/jax/experimental/mesh_utils.py#L221) in such scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8940b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mesh(array([[0, 1],\n",
       "       [2, 3]]), ('x', 'y'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh_shape = (2, 2)\n",
    "devices = np.asarray(jax.devices()).reshape(*mesh_shape)\n",
    "mesh = maps.Mesh(devices, ('x', 'y'))\n",
    "mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2025cda",
   "metadata": {},
   "source": [
    "## Step-2 Using PJIT to express partition intent\n",
    "Create a version of train_step with partitioning intent on the inputs.\n",
    "Notice that we are using 'x', 'y' mesh axis to define the partitioning for image's X and Y dimensions (spatial partitioning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e372baf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_train_step = pjit(\n",
    "    train_step,\n",
    "    in_axis_resources=(None, \n",
    "                       {'image': PartitionSpec(None, 'x', 'y', None),\n",
    "                        'label': None \n",
    "                       }\n",
    "                      ),\n",
    "    out_axis_resources=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3955e6",
   "metadata": {},
   "source": [
    "## Step-3 update other functions to use pjit version of train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ac545b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_train_epoch(state, train_ds, batch_size, epoch, rng):\n",
    "    train_ds_size = len(train_ds['image'])\n",
    "    steps_per_epoch = train_ds_size // batch_size\n",
    "    \n",
    "    perms = jax.random.permutation(rng, train_ds_size)\n",
    "    perms = perms[:steps_per_epoch * batch_size]\n",
    "    perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "    batch_metrics = []\n",
    "    for perm in perms:\n",
    "        batch = {k: v[perm, ...] for k, v in train_ds.items()}\n",
    "        state, metrics = p_train_step(state, batch)\n",
    "        batch_metrics.append(metrics)\n",
    "    batch_metrics_np = jax.device_get(batch_metrics)\n",
    "    epoch_metrics_np = {\n",
    "        k: np.mean([metrics[k] for metrics in batch_metrics_np])\n",
    "        for k in batch_metrics_np[0]\n",
    "    }\n",
    "    print(f\"train epoch: {epoch}, loss: {epoch_metrics_np['loss']}, accuracy: {epoch_metrics_np['accuracy'] * 100}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c0e3ee",
   "metadata": {},
   "source": [
    "Express similar partition intent for eval_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28eb1c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_eval_step = pjit(\n",
    "    eval_step,\n",
    "    in_axis_resources=(None, \n",
    "                       {'image': PartitionSpec(None, 'x', 'y', None),\n",
    "                        'label': None \n",
    "                       }\n",
    "                      ),\n",
    "    out_axis_resources=None\n",
    ")\n",
    "def p_eval_model(params, test_ds):\n",
    "    metrics = p_eval_step(params, test_ds)\n",
    "    metrics = jax.device_get(metrics)\n",
    "    summary = jax.tree_util.tree_map(lambda x: x.item(), metrics)\n",
    "    return summary['loss'], summary['accuracy']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6189f6a",
   "metadata": {},
   "source": [
    "# Run training with spatial partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99712111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 1, loss: 0.5606998801231384, accuracy: 78.46511602401733\n",
      " test epoch: 1, loss: 0.52, accuracy: 80.20\n",
      "train epoch: 2, loss: 0.46477749943733215, accuracy: 82.48080611228943\n",
      " test epoch: 2, loss: 0.45, accuracy: 83.08\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "    # Use a separate PRNG key to permute image data during shuffling\n",
    "    rng, input_rng = jax.random.split(rng)\n",
    "    # Run an optimization step over a training batch\n",
    "    if epoch == 1:\n",
    "        jax.profiler.start_trace(log_dir='/home/sivaibhav/profile-log')\n",
    "    with maps.Mesh(mesh.devices, mesh.axis_names):\n",
    "        state = p_train_epoch(state, train_ds, batch_size, epoch, input_rng)\n",
    "            # Evaluate on the test set after each training epoch\n",
    "        test_loss, test_accuracy = p_eval_model(state.params, test_ds)\n",
    "        print(' test epoch: %d, loss: %.2f, accuracy: %.2f' % (\n",
    "          epoch, test_loss, test_accuracy * 100))\n",
    "    if epoch == 2:\n",
    "        jax.profiler.stop_trace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fe27a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9711bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d27674c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

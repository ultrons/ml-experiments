{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "desirable-liability",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.components as comp\n",
    "import kfp.dsl as dsl\n",
    "from os import path\n",
    "import json\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "liable-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = comp.ComponentStore()\n",
    "component_path = path.join('.', 'steps')\n",
    "cs.local_search_paths.append(component_path)\n",
    "\n",
    "# Pre-built component\n",
    "caip_train_op = comp.load_component_from_url(\n",
    "            'https://raw.githubusercontent.com/kubeflow/pipelines/1.0.0/'\n",
    "            'components/gcp/ml_engine/train/component.yaml')\n",
    "\n",
    "# Hand-written component\n",
    "preprocess_op = cs.load_component('preprocess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efficient-bronze",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_example = [\"Mango\", 1, 3,6, \"Oranges\"];\n",
    "type(json.dumps(list_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "actual-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.components import func_to_container_op, InputPath, OutputPath\n",
    "\n",
    "@func_to_container_op\n",
    "def get_tuned_param_op(\n",
    "    hptune_job_id: str,\n",
    "    project_id: str, \n",
    "    common_args: InputPath('List'), \n",
    "    tuned_parameters_out: OutputPath('List')):\n",
    "    import argparse\n",
    "    from pathlib import Path\n",
    "    from googleapiclient import discovery\n",
    "    from googleapiclient import errors\n",
    "    from types import SimpleNamespace\n",
    "    import ast\n",
    "\n",
    "\n",
    "    # Modified from: https://stackoverflow.com/a/54332748\n",
    "    class NestedNamespace(SimpleNamespace):\n",
    "        def __init__(self, dictionary, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "            for key, value in dictionary.items():\n",
    "                if isinstance(value, dict):\n",
    "                    self.__setattr__(key, NestedNamespace(value))\n",
    "                elif isinstance(value, list):\n",
    "                    self.__setattr__(\n",
    "                        key,\n",
    "                        [\n",
    "                            NestedNamespace(i) if isinstance(i, dict)\n",
    "                            else i for i in value\n",
    "                        ]\n",
    "                    )\n",
    "                else:\n",
    "                    self.__setattr__(key, value)\n",
    "\n",
    "\n",
    "    def print_best_parameters(\n",
    "        project_id, hp_tune_job, filename='tuned_params', common_args='[]'\n",
    "    ):\n",
    "        # Store your full project ID in a variable in the format the API needs.\n",
    "        job_id = 'projects/{}/jobs/{}'.format(project_id, hp_tune_job)\n",
    "\n",
    "        # Build a representation of the Cloud ML API.\n",
    "        ml = discovery.build('ml', 'v1')\n",
    "\n",
    "        # Create a request to call projects.models.create.\n",
    "        request = ml.projects().jobs().get(name=job_id)\n",
    "        # Make the call.\n",
    "        try:\n",
    "            response = request.execute()\n",
    "        except errors.HttpError as err:\n",
    "            # Something went wrong, print out some information.\n",
    "            print('There was an error getting the job info, Check the details:')\n",
    "            print(err._get_reason())\n",
    "\n",
    "        job_info = NestedNamespace(response)\n",
    "        param_list = ast.literal_eval(common_args)\n",
    "        for key,value in job_info.trainingOutput.trials[0].hyperparameters.__dict__.items():\n",
    "            param_list.append('--'+key)\n",
    "            param_list.append(value)\n",
    "        # Creating the directory where the output file will be created (the directory may or may not exist).\n",
    "        Path(filename).parent.mkdir(parents=True, exist_ok=True)\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(str(param_list))\n",
    "            \n",
    "    with open(common_args) as file:\n",
    "        common_args_str = file.read().replace('\\n', '')\n",
    "    print_best_parameters(project_id, hptune_job_id, tuned_parameters_out, common_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "affected-threat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"https://3fee5ee78d7359c1-dot-us-central2.pipelines.googleusercontent.com/#/experiments/details/932a406d-eed4-427e-bb3c-57a0671cd87a\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://3fee5ee78d7359c1-dot-us-central2.pipelines.googleusercontent.com/#/runs/details/829ea924-f191-42ca-bf1a-6e99bf8f2a2b\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=829ea924-f191-42ca-bf1a-6e99bf8f2a2b)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Config parameters\n",
    "PROJECT_ID = 'pytorch-tpu-nfs'\n",
    "REGION = 'us-central1'\n",
    "FAIRSEQ_IMAGE = 'gcr.io/pytorch-tpu-nfs/fairseq-lm-train'\n",
    "\n",
    "hpt_input_json = './steps/hypertune/config.yaml'\n",
    "with open(hpt_input_json) as f:\n",
    "    hpt_input = json.dumps(yaml.safe_load(f)['trainingInput'])\n",
    "\n",
    "training_input_json = './steps/training/config.yaml'\n",
    "with open(training_input_json) as f:\n",
    "    training_input = json.dumps(yaml.safe_load(f)['trainingInput'])\n",
    "\n",
    "common_args = json.dumps([\n",
    "        '--task', 'language_modeling',\n",
    "        '--save-dir', 'checkpoints/transformer_wikitext-103',\n",
    "        '--arch', 'transformer_lm', '--share-decoder-input-output-embed',\n",
    "        '--dropout', '0.1',\n",
    "        '--optimizer', 'adam', '--adam-betas', '(0.9,0.98)',\n",
    "        '--clip-norm', '0.0',\n",
    "        '--lr-scheduler', 'inverse_sqrt',\n",
    "        '--warmup-updates', '4000',\n",
    "        '--warmup-init-lr', '1e-07',\n",
    "        '--tokens-per-sample', '512',\n",
    "        '--sample-break-mode', 'none',\n",
    "        '--max-tokens', '1024',\n",
    "        '--update-freq', '16',\n",
    "        '--fp16',\n",
    "        '--max-update', '500',\n",
    "    ])\n",
    "\n",
    "pipeline_args = {\n",
    "    'project_id': PROJECT_ID,\n",
    "    'region': REGION,\n",
    "    'args': common_args,\n",
    "    'master_image_uri': FAIRSEQ_IMAGE,\n",
    "    'training_input': training_input,\n",
    "    'hpt_input': hpt_input,\n",
    "    'job_id_prefix': '',\n",
    "    'job_id': '',\n",
    "    'wait_interval': '30',\n",
    "    'dataset_bucket': 'gs://kfp-exp/fairseq-lm-data'\n",
    "        }\n",
    "\n",
    "\n",
    "@dsl.pipeline(\n",
    "        name='KFP-Pipelines Example',\n",
    "        description='Kubeflow pipeline using pre-built components'\n",
    "        )\n",
    "def pipeline(\n",
    "    project_id=PROJECT_ID,\n",
    "    region=REGION,\n",
    "    args=common_args,\n",
    "    master_image_uri=FAIRSEQ_IMAGE,\n",
    "    training_input=training_input,\n",
    "    hpt_input=hpt_input,\n",
    "    job_id_prefix='',\n",
    "    job_id='',\n",
    "    wait_interval='30',\n",
    "    dataset_bucket='gs://kfp-exp/fairseq-lm-data'\n",
    "):\n",
    "    \"\"\" Pipeline (DAG) definition \"\"\"\n",
    "\n",
    "    preprocess = preprocess_op (\n",
    "            dataset_bucket=dataset_bucket,\n",
    "            args_in=args\n",
    "            )\n",
    "\n",
    "    hypertune = caip_train_op(\n",
    "        project_id=project_id,\n",
    "        region=region,\n",
    "        args=preprocess.outputs['args_out'],\n",
    "        master_image_uri=master_image_uri,\n",
    "        training_input=hpt_input,\n",
    "        job_id_prefix=job_id_prefix,\n",
    "        job_id=job_id,\n",
    "        wait_interval=wait_interval\n",
    "        ).set_display_name(\"Hyperparameter-Tuning\")\n",
    "    hypertune.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "\n",
    "    get_tuned_param = get_tuned_param_op(\n",
    "           project_id=project_id,\n",
    "           hptune_job_id=hypertune.outputs['job_id'],\n",
    "           common_args=preprocess.outputs['args_out']\n",
    "    ).set_display_name(\"Get-Tuned-Param\")\n",
    "\n",
    "    train = caip_train_op(\n",
    "        project_id=project_id,\n",
    "        region=region,\n",
    "        args=get_tuned_param.outputs['tuned_parameters_out'],\n",
    "        master_image_uri=master_image_uri,\n",
    "        training_input=training_input,\n",
    "        job_id_prefix=job_id_prefix,\n",
    "        job_id=job_id,\n",
    "        wait_interval=wait_interval\n",
    "        ).set_display_name(\"Training\")\n",
    "\n",
    "\n",
    "client = kfp.Client(host='https://3fee5ee78d7359c1-dot-us-central2.pipelines.googleusercontent.com')\n",
    "client.create_run_from_pipeline_func(pipeline, pipeline_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-hearing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.mnightly-2021-01-20-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:mnightly-2021-01-20-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
